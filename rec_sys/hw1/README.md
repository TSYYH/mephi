Посмотреть работу можно по ссылке[ссылке](./Сырников_hw1.ipynb)

# Этап 1: знакомство с данными и EDA

В распределении оценок наблюдается смещение в сторону высоких оценок:

<img width="575" height="444" alt="image" src="https://github.com/user-attachments/assets/af7877ac-6116-44ba-826b-23c5f4252a73" />

Почти все пользователи достаточно активны, но по краям распределения всё еще находится достаточное количество пользователей чтобы говорить о проблеме холодного старта:

<img width="632" height="459" alt="image" src="https://github.com/user-attachments/assets/2870fefb-f4c0-4d49-b978-49f71ab670ef" />

<img width="307" height="474" alt="image" src="https://github.com/user-attachments/assets/46ac85f5-9ba0-4fa5-aa20-1e14103bd5a2" />

Наблюдается небольшое число очень популярных книг (длинный хвост). Большинство книг имеют мало оценок

<img width="603" height="454" alt="image" src="https://github.com/user-attachments/assets/f02b63ac-681b-4d0a-a599-0762c5b27680" />

<img width="297" height="163" alt="image" src="https://github.com/user-attachments/assets/55cfbf3a-85c2-4201-bbbf-16517ced7808" />

После очистки популярные теги выглядят так:

<img width="964" height="704" alt="image" src="https://github.com/user-attachments/assets/7f174095-1249-4660-8e4e-ca827748924f" />

## Основные проблемы данных

1. Разреженность. Каждый пользователь оценивает малую долю книг. Большинство пользователей оставили небольшое число оценок (хвост)

2. Смещение популярности. Распределение количества оценок по книгам неравномерно (длинный хвост). Небольшая группа книг получает больше внимания пользователей

3. Смещение оценок в сторону высоких значений

4. Значительная часть пользователей имеет мало взаимадойствий. Для них коллаборативные модели не применимы.


Уже на этапе EDA становится ясно, что ни один подход в одиночку не будет оптимальным. Это обосновывает использование нескольких моделей и гибридной рекомендательной системы в последующих этапах.

# Этап 2: базовые и контентные модели

Была реализована неперсонализированная модель Top-N самых популярных книг (по среднему рейтингу с порогом минимального количества оценок). Разультат еёё работы:

<img width="555" height="386" alt="image" src="https://github.com/user-attachments/assets/1bc02d84-650a-4c25-b381-9e18b0a9681a" />

Была реализована контентная модель Top-N самых похожих книг по косинусной мере близости между их TF-IDF-векторами. Разультат еёё работы:

<img width="423" height="390" alt="image" src="https://github.com/user-attachments/assets/596eb2a1-270d-420e-9188-9104158e540f" />

# Этап 3: коллаборативная фильтрация

Реализована Item-Based Collaborative Filtering. Результат предсказания оценки для книги:

<img width="389" height="66" alt="image" src="https://github.com/user-attachments/assets/c45c3705-7180-4e5b-925f-bf2e6626a2c0" />

## Вычислительная сложность

### Время

Построение матрицы пользователь-книга - O(N), N-число рейтингов

Центрирование по среднему рейтингу книги - O(N * M), N - число пользователей, M - число книг

Вычисление матрицы схожести книг - O(N^2 * M), N - число книг, M - число пользователей

Предсказание рейтинга для одного пользователя - O(N * log N + K), N - число книг, K - K похожих

### Память

Матрица - O(I^2)

### Оптимизации для больших данных

Сохранять только K наиболее похожих книг, sparse-матрицы, Approximate Nearest Neighbors

# Этап 4: матричные разложения

Была обучена модель SVD, оценка RMSE на тесте:

<img width="182" height="44" alt="image" src="https://github.com/user-attachments/assets/3f4f628d-ec5c-4ea6-99ff-75be476f0e63" />

Реализована функция get_recommendations(user_id, N=5), которая для заданного пользователя возвращает топ-N книг с наибольшим предсказанным рейтингом, её вывод:

<img width="434" height="243" alt="image" src="https://github.com/user-attachments/assets/fa9f1b0f-6f82-4e12-a7c0-2abead81ea46" />

# Этап 5: оценка и сравнение моделей

Для моделей были рассчитаны метрики Precision@K, Recall@K, nDCG@K. Релевантными книгами считались с оценкой от пользлователя >= 4. Метрики:

<img width="348" height="161" alt="image" src="https://github.com/user-attachments/assets/58b96b82-e5eb-4201-867b-7dd9c46641e4" />

# Этап 6: гибридизация и выводы

## 6.1 Гибридный подход для борьбы с холодным стартом

Новые книги (мало или нет оценок)

Для книг, не имеющих достаточного количества пользовательских оценок, используются контентные рекомендации. Такой подход не требует истории взаимодействий и позволяет рекомендовать новые книги на основе их семантического содержания.

Новые пользователи

Для пользователей без истории взаимодействий применяется неперсонализированная модель Popularity. Данный подход обеспечивает разумное стартовое качество рекомендаций и служит надёжным бейзлайном при отсутствии пользовательских данных.

Известные пользователи и книги

При наличии достаточного числа оценок используется модель матричной факторизации SVD, демонстрирующая наилучшее качество рекомендаций. Модель эффективно захватывает латентные факторы пользователей и книг, что позволяет учитывать скрытые предпочтения и формировать персонализированные рекомендации.

## 6.2 Выводы по качеству моделей

Низкие абсолютные значения метрик Precision@K, Recall@K и nDCG@K обусловлены высокой разреженностью данных, большим размером каталога и строгим протоколом оценки, при котором релевантные книги полностью исключаются из обучающей выборки. В таких условиях вероятность случайного попадания релевантного объекта в топ-N рекомендаций существенно снижается.

При этом относительное сравнение моделей остаётся информативным:

Модель SVD стабильно превосходит Popularity и Item-Based CF по всем метрикам. Это объясняется тем, что SVD моделирует латентные факторы и скрытые предпочтения пользователей, а также менее чувствительна к разреженности данных по сравнению с классическими методами коллаборативной фильтрации.

Item-Based Collaborative Filtering показывает худшие результаты из-за экстремальной разреженности матрицы пользователь-книга и жёсткого исключения книг, уже присутствующих в обучающей выборке. В таких условиях надёжная оценка схожести между объектами становится затруднительной.

Popularity рекомендует одни и те же книги всем пользователям и не учитывает индивидуальные предпочтения. Тем не менее, модель иногда демонстрирует ненулевые значения метрик за счёт случайного совпадения релевантных книг с популярными позициями, особенно для пользователей, читавших широко известные книги.

Контентная модель показывает самые низкие значения метрик, поскольку она не использует информацию о пользовательских оценках и не оптимизируется под ранжирование релевантных для конкретного пользователя объектов. Однако её ценность заключается в возможности решения задачи холодного старта для новых книг.

## 6.3 Возможные направления улучшения

Для дальнейшего повышения качества рекомендаций можно предложить следующие направления развития:

Улучшение текстовых представлений: заменить TF-IDF на Word2Vec / FastText для учёта семантики слов, BERT или Sentence-BERT для контекстных представлений описаний книг.

Расширение набора признаков: жанры, авторов, год публикации, агрегированные характеристики пользователей (любимые жанры, средний рейтинг).

Нейросетевые подходы: Neural Collaborative Filtering, автоэнкодеры для матричных разложений, гибридные нейросетевые архитектуры, объединяющие текст и взаимодействия.

Улучшение гибридизации: взвешенное объединение скорингов моделей, обучение метамодели (learning-to-rank).
